<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="KO">
<meta name="dcterms.date" content="2018-01-01">
<meta name="description" content="notes for part 3 of the deeplearning.ai course">

<title>khalido.org - deeplearning.ai: Structuring Machine Learning Projects</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">khalido.org</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/khalido" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/KO" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">deeplearning.ai: Structuring Machine Learning Projects</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          notes for part 3 of the deeplearning.ai course
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">courses</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>KO </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 1, 2018</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#deeplearning.ai-structuring-machine-learning-projects" id="toc-deeplearning.ai-structuring-machine-learning-projects" class="nav-link active" data-scroll-target="#deeplearning.ai-structuring-machine-learning-projects">deeplearning.ai: Structuring Machine Learning Projects</a>
  <ul class="collapse">
  <li><a href="#week-1-ml-strategy" id="toc-week-1-ml-strategy" class="nav-link" data-scroll-target="#week-1-ml-strategy">Week 1: ML Strategy</a>
  <ul class="collapse">
  <li><a href="#orthogonalization" id="toc-orthogonalization" class="nav-link" data-scroll-target="#orthogonalization">Orthogonalization</a></li>
  <li><a href="#setting-up-your-goal" id="toc-setting-up-your-goal" class="nav-link" data-scroll-target="#setting-up-your-goal">Setting up your goal</a></li>
  <li><a href="#comparing-to-human-level-performance" id="toc-comparing-to-human-level-performance" class="nav-link" data-scroll-target="#comparing-to-human-level-performance">Comparing to human-level performance</a></li>
  <li><a href="#andrej-karpathy-interview" id="toc-andrej-karpathy-interview" class="nav-link" data-scroll-target="#andrej-karpathy-interview">Andrej Karpathy interview</a></li>
  </ul></li>
  <li><a href="#week-2-more-ml-strategy" id="toc-week-2-more-ml-strategy" class="nav-link" data-scroll-target="#week-2-more-ml-strategy">Week 2: More ML Strategy</a>
  <ul class="collapse">
  <li><a href="#error-analysis" id="toc-error-analysis" class="nav-link" data-scroll-target="#error-analysis">Error Analysis</a></li>
  <li><a href="#mismatched-training-and-devtest-data" id="toc-mismatched-training-and-devtest-data" class="nav-link" data-scroll-target="#mismatched-training-and-devtest-data">Mismatched training and dev/test data</a></li>
  <li><a href="#learning-from-multiple-tasks" id="toc-learning-from-multiple-tasks" class="nav-link" data-scroll-target="#learning-from-multiple-tasks">Learning from multiple tasks</a></li>
  <li><a href="#end-to-end-deep-learning" id="toc-end-to-end-deep-learning" class="nav-link" data-scroll-target="#end-to-end-deep-learning">End-to-end deep learning</a></li>
  <li><a href="#ruslan-salakhutdinov-interview" id="toc-ruslan-salakhutdinov-interview" class="nav-link" data-scroll-target="#ruslan-salakhutdinov-interview">Ruslan Salakhutdinov interview</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="deeplearning.ai-structuring-machine-learning-projects" class="level1">
<h1>deeplearning.ai: Structuring Machine Learning Projects</h1>
<p>This course covers how to think about and improve machine learning systems.</p>
<blockquote class="blockquote">
<p>You will learn how to build a successful machine learning project. If you aspire to be a technical leader in AI, and know how to set direction for your team’s work, this course will show you how.</p>
</blockquote>
<p><strong>Course Resources</strong></p>
<ul>
<li><p><a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome">Course home</a></p></li>
<li><p><a href="https://www.coursera.org/learn/machine-learning-projects/discussions">Discussion forum</a></p></li>
<li><p><a href="#week-1-ml-strategy">Week 1: ML Strategy</a></p>
<ul>
<li><a href="#orthogonalization">Orthogonalization</a></li>
<li><a href="#setting-up-your-goal">Setting up your goal</a>
<ul>
<li><a href="#single-number-evaluation-metric">Single number evaluation metric</a></li>
<li><a href="#satisficing-and-optimizing-metric">Satisficing and Optimizing metric</a></li>
<li><a href="#traindevtest-distributions">Train/dev/test distributions</a></li>
<li><a href="#size-of-the-dev-and-test-sets">Size of the dev and test sets</a></li>
<li><a href="#when-to-change-devtest-sets-and-metrics">When to change dev/test sets and metrics</a></li>
</ul></li>
<li><a href="#comparing-to-human-level-performance">Comparing to human-level performance</a>
<ul>
<li><a href="#why-human-level-performance">Why human-level performance?</a></li>
<li><a href="#avoidable-bias">Avoidable bias</a></li>
<li><a href="#understanding-human-level-performance">Understanding human-level performance</a></li>
<li><a href="#surpassing-human-level-performance">Surpassing human-level performance</a></li>
<li><a href="#improving-your-model-performance">Improving your model performance</a></li>
</ul></li>
<li><a href="#andrej-karpathy-interview">Andrej Karpathy interview</a></li>
</ul></li>
<li><p><a href="#week-2-more-ml-strategy">Week 2: More ML Strategy</a></p>
<ul>
<li><a href="#error-analysis">Error Analysis</a>
<ul>
<li><a href="#carrying-out-error-analysis">Carrying out error analysis</a></li>
<li><a href="#cleaning-up-incorrectly-labeled-data">Cleaning up incorrectly labeled data</a></li>
<li><a href="#build-your-first-system-quickly-then-iterate">Build your first system quickly, then iterate</a></li>
</ul></li>
<li><a href="#mismatched-training-and-devtest-data">Mismatched training and dev/test data</a>
<ul>
<li><a href="#training-and-testing-on-different-distributions">Training and testing on different distributions</a></li>
<li><a href="#bias-and-variance-with-mismatched-data-distributions">Bias and Variance with mismatched data distributions</a></li>
<li><a href="#addressing-data-mismatch">Addressing data mismatch</a></li>
</ul></li>
<li><a href="#learning-from-multiple-tasks">Learning from multiple tasks</a>
<ul>
<li><a href="#transfer-learning">Transfer learning</a></li>
<li><a href="#multi-task-learning">Multi-task learning</a></li>
</ul></li>
<li><a href="#end-to-end-deep-learning">End-to-end deep learning</a>
<ul>
<li><a href="#what-is-end-to-end-deep-learning">What is end-to-end deep learning</a></li>
<li><a href="#whether-to-use-end-to-end-deep-learning">Whether to use end-to-end deep learning</a></li>
</ul></li>
<li><a href="#ruslan-salakhutdinov-interview">Ruslan Salakhutdinov interview</a></li>
</ul></li>
</ul>
<section id="week-1-ml-strategy" class="level2">
<h2 class="anchored" data-anchor-id="week-1-ml-strategy">Week 1: ML Strategy</h2>
<p>There are lots of ways to improve a deep learning system, so its important to sse quick and effective ways to figure out the most promising things to try and and improve.</p>
<section id="orthogonalization" class="level3">
<h3 class="anchored" data-anchor-id="orthogonalization">Orthogonalization</h3>
<ul>
<li>old school tv’s had a number of knobs to tune the picture - all the settings made it very hard to get the picture perfect</li>
<li>cars have orthogonal controls - a steering and speed which effect two different things making it easier to control. If we have controls which effect the steering and speed at the same time it would make it much harder to get the speed and steering angle we wanted.</li>
<li>we have a chain of assumptions in ML: fit training set on cost func, fit dev set, fit test set, then perform well in the real world and we want to have different set of knobs to tune each part.</li>
<li>ideally we have a number of controls which do one task well without effecting other things too much.</li>
<li>of course, some controls apply across many layers and are still useful, like early stopping</li>
</ul>
</section>
<section id="setting-up-your-goal" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-your-goal">Setting up your goal</h3>
<section id="single-number-evaluation-metric" class="level4">
<h4 class="anchored" data-anchor-id="single-number-evaluation-metric">Single number evaluation metric</h4>
<ul>
<li>set up a single real number to evaluate performance before starting out on a project</li>
<li>a well defined dev set and a single metric speeds up the iterative process of developing a good model</li>
<li>looking at a simple cat classifier:</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>Classifier</th>
<th>Precision</th>
<th>Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>95%</td>
<td>90%</td>
</tr>
<tr class="even">
<td>B</td>
<td>98%</td>
<td>85%</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Precision</strong>: of the examples our classifier says are cats, what percentage is actually right</li>
<li><strong>Recall</strong>: what % of actual cats are correctly classified</li>
<li>The problem with using precision and recall is it can make it hard to figure out which classifier is better</li>
<li><a href="https://www.wikiwand.com/en/F1_score">F1 Score</a> is the harmonic average of precision and recall using <span class="math inline">\(F1 = 2 / ((1/P) + (1/R))\)</span> or <span class="math inline">\(2 * (precision * recall) / (precision + recall)\)</span>
<ul>
<li>F1 score is usefeul as it balances precision and recall, rather than just taking the simple average, which would favour outliers</li>
</ul></li>
<li>to summarize, have a single number metric (this could be an average of several metrics) and a good dev set</li>
</ul>
</section>
<section id="satisficing-and-optimizing-metric" class="level4">
<h4 class="anchored" data-anchor-id="satisficing-and-optimizing-metric">Satisficing and Optimizing metric</h4>
<ul>
<li>its not easy to setup a single number - we might narrow things down to a single number, accuracy, but also want to evaluate running time</li>
<li>solve this by picking one metric to optimize, and satisfy the other metric by picking a threshold, like all running times below 1000ms are good enough.
<ul>
<li>for voice recognition, like on Amazon Alexa, we have metrics for how long humans are ok to wait, so we can just use that number as a threshold</li>
</ul></li>
<li>so, we have a make metric to optimize, and any number of other metrics which we satisfy with thresholds.</li>
</ul>
<p>#### Train/dev/test distributions</p>
<ul>
<li>dev (cross validation set) and test (the final holdout data) sets have to come from the same distribution.</li>
<li>for example, if we have data from different regions, don’t say us/uk/europe is the dev set and asia is the test set - regions will have differences.</li>
<li>an ML team wasted time optimizing loan approvals on medium income zip codes, but was testing on low income zip codes.</li>
<li>choose a dev and test set to reflect data you expect to get in the future and consider important to do well on.</li>
</ul>
</section>
<section id="size-of-the-dev-and-test-sets" class="level4">
<h4 class="anchored" data-anchor-id="size-of-the-dev-and-test-sets">Size of the dev and test sets</h4>
<ul>
<li>old rule of thumb for train/dev/test: 60/20/20 - worked for smaller data.</li>
<li>but now we have much larger data sets, so for 1M data set, 1% or 10K might be enough for a test set.</li>
<li>deep learning is data hungry so we want to feed it as much data as possible for training</li>
<li>the test set helps us evaluate the overall system, so it has to be big enough to give us high confidence.
<ul>
<li>this will vary depending on the data set.</li>
<li>sometimes we might not need a test set at all.</li>
</ul></li>
</ul>
</section>
<section id="when-to-change-devtest-sets-and-metrics" class="level4">
<h4 class="anchored" data-anchor-id="when-to-change-devtest-sets-and-metrics">When to change dev/test sets and metrics</h4>
<ul>
<li>say we’ve built two cat classifiers, A has 3% error, B has 5% error.</li>
<li>A is better, but lets through porn images. B stops all the porn images, so even though it has higher error, B is better algorithm.</li>
<li>so we want to change our metrics here, say adding a weight to penalize porn images</li>
<li>think of machine learning as having two separate steps:
<ul>
<li><ol type="1">
<li>figure out the metric</li>
</ol></li>
<li><ol start="2" type="1">
<li>worry about how to actually do well on the metric</li>
</ol></li>
</ul></li>
<li>other things happen, like our image classifier performs well on our data set, but users upload bad quality pictures which lower performance, so change metric and/or the dev set to better capture what we need our algorithm to actually do.</li>
</ul>
</section>
</section>
<section id="comparing-to-human-level-performance" class="level3">
<h3 class="anchored" data-anchor-id="comparing-to-human-level-performance">Comparing to human-level performance</h3>
<section id="why-human-level-performance" class="level4">
<h4 class="anchored" data-anchor-id="why-human-level-performance">Why human-level performance?</h4>
<ul>
<li>two main reasons we compare to human level performance:
<ul>
<li>ML is getting better so its become feasible to compare to human level performance in many applications.</li>
<li>the workflow of designing and building ML systems is much more efficient when comparing to what humans also do.</li>
</ul></li>
<li>for many problems, progress is rapid approaching human level performance, and slows down upon reaching it. the hope is that its reaching a theoretical limit, called the Bayes optimal error.</li>
<li><strong>Bayes optimal error</strong> is the best possible error
<ul>
<li>for tasks humans are good at, there isn’t much range b/w human error and the bayes optimal error.</li>
</ul></li>
<li>when our ML algo is worse than humans, get humans to:
<ul>
<li>give us more data, like label images, translate text, etc.</li>
<li>manual analysis errors - why did a human get it right and algo get it wrong?</li>
<li>better analysis of bias/variance</li>
</ul></li>
</ul>
</section>
<section id="avoidable-bias" class="level4">
<h4 class="anchored" data-anchor-id="avoidable-bias">Avoidable bias</h4>
<ul>
<li>humans are great at image classification, so looking at two image classification algos:</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Bias Example</th>
<th>Variance Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Humans</td>
<td>1%</td>
<td>7.5%</td>
</tr>
<tr class="even">
<td>Training error</td>
<td>8%</td>
<td>8%</td>
</tr>
<tr class="odd">
<td>Dev Error</td>
<td>10%</td>
<td>10%</td>
</tr>
</tbody>
</table>
<ul>
<li>the left example illustrates bias - since humans are doing much better than the algo, we focus on improving training error.</li>
<li>the right example shows that we are close to human error - so we focus on reducing the variance</li>
<li>if we are doing better than Bayes error we’re overfitting.</li>
<li>having an estimate of the bayes optimal error helps us to focus on whether to reduce bias or variance.
<ul>
<li>avoidable bias: training error - human level error</li>
<li>variance: dev error - training error</li>
</ul></li>
</ul>
</section>
<section id="understanding-human-level-performance" class="level4">
<h4 class="anchored" data-anchor-id="understanding-human-level-performance">Understanding human-level performance</h4>
<ul>
<li>there are multiple levels of human performance - choose what matters and what we want to achieve for our system
<ul>
<li>do we use a typical doctors error level, an experienced doctors, or the lower error level from a team of experienced doctors.</li>
<li>surpassing an average radiologist might mean our system is good enough to deploy</li>
</ul></li>
<li>use human level error as a proxy for Bayes error.</li>
<li>An error analysis example from medical classification, where say human error ranges from 0.5-1%:</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>Error</th>
<th>Bias Example</th>
<th>Variance Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Human/Bayes</td>
<td>1%</td>
<td>1%</td>
</tr>
<tr class="even">
<td>Training</td>
<td>5%</td>
<td>1%</td>
</tr>
<tr class="odd">
<td>Dev</td>
<td>6%</td>
<td>5%</td>
</tr>
</tbody>
</table>
<ul>
<li>the left column we need to concentrate on reducing the training error - the variance, and the human error we pick doesn’t matter.</li>
<li>the right col we need to concentrate on the dev error - i.e the variance, and picking the lower range of human error is more important since we are close to human level performance.</li>
<li>so we have a more nuanced view of error, and using bayes error instead of zero error leads to better and faster decisions on reducing bias or variance.</li>
</ul>
</section>
<section id="surpassing-human-level-performance" class="level4">
<h4 class="anchored" data-anchor-id="surpassing-human-level-performance">Surpassing human-level performance</h4>
<ul>
<li>ml gets harder as we approach/surpass human level performance</li>
<li>when we’ve surpassed human level performance, are we overfitting, or is the bayes error lower than human error.</li>
<li>some applications have surpassed human level: online advertising, product recommendation, loan approval, logistics
<ul>
<li>all these examples are learning from structured data, not natural perception problems which humans are very good at</li>
<li>teams have access to heaps of data</li>
</ul></li>
<li>computers haven gotten to single human level at certain perception tasks, like image recognition, speech.</li>
</ul>
</section>
<section id="improving-your-model-performance" class="level4">
<h4 class="anchored" data-anchor-id="improving-your-model-performance">Improving your model performance</h4>
<ul>
<li>two fundamental assumptions of supervised learning:
<ul>
<li>we can fit the training set pretty well, or avoid bias</li>
<li>the training set performance generalizes well to the dev/test set - achieve low variance</li>
</ul></li>
<li>to improve a deep learning supervised system</li>
<li>for improving bias:
<ul>
<li>train bigger model</li>
<li>train longer or use better optimization algo (RMSprop, Adam, momentum, etc)</li>
<li>try other model architectures, hyperparameter search</li>
</ul></li>
<li>improve variance:
<ul>
<li>more data</li>
<li>regularization (L2, dropout, data augmentation)</li>
<li>NN architecture, hyperparameter search</li>
</ul></li>
<li></li>
</ul>
</section>
</section>
<section id="andrej-karpathy-interview" class="level3">
<h3 class="anchored" data-anchor-id="andrej-karpathy-interview">Andrej Karpathy interview</h3>
<ul>
<li>before NN’s ml/ai was a lot of graphs, tree pruning, not very satisfying - NN’s actually felt like AI vs the old school AI techniques</li>
<li>before, humans wrote code to do something, with neural networks / machine learning humans write the optimization algo and specify inputs/outputs and the computers write code</li>
<li>while working on cifar10, had predicted an error rate of 10%, but we’re now down to 2-3%.</li>
<li>built a javascript interface to show himself imagenet images and classify them</li>
<li>famous for putting his deep learning stanford class online</li>
<li>understand of deep learning has changed:
<ul>
<li>surprised by how general deep learning is - no one saw how well it would work</li>
</ul></li>
<li>amazed at how you can take pre trained networks and apply them to other tasks</li>
<li>people are crushing tasks one after the other with transfer learning</li>
<li>surprised that unsupervised learning hasn’t worked so well</li>
<li>has been thinking about the future of AI, thinks will split into two directions:
<ul>
<li>applied AI, where ppl train NN’s to do something, generally supervised learning</li>
<li>artificial general intelligence, working on dynamic systems to do everything a human can</li>
</ul></li>
<li>thinks the approach to do one thing at a time, like with current neural nets which recoginze images, or do speech etc, won’t lead to AGI, we need a single kind of NN which learns all the tasks a human can do - see <a href="http://karpathy.github.io/2015/11/14/ai/">his short story on how this might look</a>.</li>
<li>people liked CS213N becuase it didn’t abstract away things, it works through the low-level details. Implementing stuff is the best way to learn it.</li>
</ul>
</section>
</section>
<section id="week-2-more-ml-strategy" class="level2">
<h2 class="anchored" data-anchor-id="week-2-more-ml-strategy">Week 2: More ML Strategy</h2>
<section id="error-analysis" class="level3">
<h3 class="anchored" data-anchor-id="error-analysis">Error Analysis</h3>
<section id="carrying-out-error-analysis" class="level4">
<h4 class="anchored" data-anchor-id="carrying-out-error-analysis">Carrying out error analysis</h4>
<ul>
<li>manually examining what your algo is doing gives insight
<ul>
<li>e.g looking at a 100 misclassified dev set examples, see whats the biggest type of error and work on fixing that. i.e we want to work on the errors which make up the bulk of our problem, rather than the lower percentage errors.</li>
</ul></li>
<li>error analysis helps us pick useful actions which will have meaningful improvements.</li>
<li>we can evaluate multiple ideas in parallel - use a spreadsheet to help decide:</li>
</ul>
<p><img src="img/eval-multiple-ideas.png" class="img-fluid"></p>
<ul>
<li>so summarize errors, find categories, prioritize important ones</li>
</ul>
</section>
<section id="cleaning-up-incorrectly-labeled-data" class="level4">
<h4 class="anchored" data-anchor-id="cleaning-up-incorrectly-labeled-data">Cleaning up incorrectly labeled data</h4>
<ul>
<li>sometimes its worthwhile to check training sets for mislabelled images
<ul>
<li>deep neural networks are quite robust to random errors in the training set, so few mistakes are ok</li>
<li>but systematic errors aren’t ok, like labelling all white dogs as cats</li>
</ul></li>
<li>modify our error spreadsheet above to have a mis-labelled category, we should always go after the biggest cause of error first</li>
<li>correcting dev/test set examples:
<ul>
<li>apply same process to dev/test so they continue to come from the same distribution</li>
<li>consider examining examples the algo got right as well as the ones it got wrong</li>
<li>we might decide to only correct labels in the dev/test sets and not go through the bigger training set, so dev/test data may now come from slightly different distrubutions. This is ok, long as both dev/test have the same distribution, and the train set is a slightly different distribution</li>
</ul></li>
</ul>
</section>
<section id="build-your-first-system-quickly-then-iterate" class="level4">
<h4 class="anchored" data-anchor-id="build-your-first-system-quickly-then-iterate">Build your first system quickly, then iterate</h4>
<ul>
<li>there are many ways to make a speech recognition system more robust. More generally, for any ML project there are 50 different directions to improve a ml system</li>
<li>quickly set up a dev/test set and metric, build a initial system, then use Bias/Variance analysis and error analysis to prioritize next steps</li>
<li>a lot of value in the initial ML system is to help us prioritize future efforts.</li>
</ul>
</section>
</section>
<section id="mismatched-training-and-devtest-data" class="level3">
<h3 class="anchored" data-anchor-id="mismatched-training-and-devtest-data">Mismatched training and dev/test data</h3>
<section id="training-and-testing-on-different-distributions" class="level4">
<h4 class="anchored" data-anchor-id="training-and-testing-on-different-distributions">Training and testing on different distributions</h4>
<ul>
<li>deep learning needs big data, so often teams end up shoving whatever they can find into a training set, so you end up with different distributions b/w train and test/dev sets.</li>
<li>e.g we can get 200k cat pictures from web pages, which are good quality and in large numbers, and 10k pictures from a mobile app which are crappy.</li>
<li>so what can we do:
<ul>
<li>combine the datasets and randomly shuffle into a train/dev/test split (205k, 2,500, 2,500), so everything is from the same distribution
<ul>
<li>the problem here is that 2,381 out of 2,500 images in the dev/test set will come from the mobile app</li>
</ul></li>
<li>make the training set use all 200k from the web plus 5K from the app, and test/dev set will be 2,500 images each from the app. This sets the target what we want it to be, even though the distributions are no different.</li>
</ul></li>
<li>a real example of a speech recognizer for directions - we are only listening for sentences like “find the nearest gas station” but we can train on all kinds of speech data, while the dev/test sets are from our specific area. If our specific application has enough data we can add some of it to the training set as well.</li>
</ul>
</section>
<section id="bias-and-variance-with-mismatched-data-distributions" class="level4">
<h4 class="anchored" data-anchor-id="bias-and-variance-with-mismatched-data-distributions">Bias and Variance with mismatched data distributions</h4>
<ul>
<li>the way we analyze bias and variance changes when train dev/test sets are from different distributions</li>
<li>so we need a training-dev set which has the same distribution as the training set, and isn’t used for training. so we would have error analysis like:</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Variance Problem</th>
<th>data mismatch Problem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training Error</td>
<td>1%</td>
<td>1%</td>
</tr>
<tr class="even">
<td>Training-dev error</td>
<td>9%</td>
<td>1.5%</td>
</tr>
<tr class="odd">
<td>Dev Error</td>
<td>10%</td>
<td>10%</td>
</tr>
</tbody>
</table>
</section>
<section id="addressing-data-mismatch" class="level4">
<h4 class="anchored" data-anchor-id="addressing-data-mismatch">Addressing data mismatch</h4>
<ul>
<li>carry out manual error analysis to understand difference b/w training and dev/test sets</li>
<li>we might find errors like a lot of our dev/test data is nosier than training set</li>
<li>so then we can collect more training data, or make it similar to dev/test data</li>
<li>use artificial data synthesis to make the training data more similar to dev set:
<ul>
<li>combine some of the training data with something to make it similar to the test/dev distribution, like recorded background noise, or generate new examples</li>
</ul></li>
<li>be careful about simulating data from a small subset of space, like background noise which isn’t representative of actual background noise</li>
<li>we can synthesize data which passes the human test but it could lead to over fitting as our synthetic data might just be making a subset of the dataset.</li>
</ul>
</section>
</section>
<section id="learning-from-multiple-tasks" class="level3">
<h3 class="anchored" data-anchor-id="learning-from-multiple-tasks">Learning from multiple tasks</h3>
<section id="transfer-learning" class="level4">
<h4 class="anchored" data-anchor-id="transfer-learning">Transfer learning</h4>
<ul>
<li>apply knowledge from one task to another</li>
<li>take a image recognizer NN, delete the last layer, create a new layer with random weights and retrain the NN on the new dataset. (called fine tuning)
<ul>
<li>we can train only the last layer, or given enough data we can train the entire network.</li>
<li>this works as a lot of the low level layers are recognizing structures and features which transfers across to different tasks</li>
</ul></li>
<li>transfer learning makes sense when:
<ul>
<li>task A and B have the same input X (image, speech)</li>
<li>we have a lot of data for task A and less data for task B</li>
<li>the low level features are similar for both tasks</li>
</ul></li>
<li>obviously, having a large dataset for the actual problem is ideal, but often we end up having better/more data for a well known problem, like ImageNet for images, and a lot less for what we want to do (say radiology photos).</li>
</ul>
</section>
<section id="multi-task-learning" class="level4">
<h4 class="anchored" data-anchor-id="multi-task-learning">Multi-task learning</h4>
<ul>
<li>try to have one NN learn multiple tasks - like a simple self driving car has to detect several things: stop signs, pedestrians, cars, traffic lights, etc</li>
<li>so the NN predicts a output vector where each position indicates whether something is there or not. (one image has multiple labels)</li>
<li>we could have a NN for each type of object, so when does multi-task learning make sense?
<ul>
<li>low level features are shared across each object.</li>
<li>the amount of data for each task is similar</li>
<li>can train a big enough NN to do well on all tasks (can perform better than single NNs)</li>
</ul></li>
<li>in practice, multi-task is used a lot less than transfer learning - though is used a lot in computer vision</li>
</ul>
</section>
</section>
<section id="end-to-end-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="end-to-end-deep-learning">End-to-end deep learning</h3>
<section id="what-is-end-to-end-deep-learning" class="level4">
<h4 class="anchored" data-anchor-id="what-is-end-to-end-deep-learning">What is end-to-end deep learning</h4>
<ul>
<li>there are some learning systems which need multiple stages of processing, like speech recognition and vision - engineers had spent years engineering feature pipelines</li>
<li>and end to end deep learning neural network replaces all these multiple stages with a single neural network</li>
<li>but sometimes you don’t want to just feed raw data, like with face recognition - it works better if the image is zoomed and cropped to the face - so you have two deep learning stages:
<ul>
<li>figure out where is the face</li>
<li>now figure out whose face it is</li>
</ul></li>
<li>when we have heaps of data, like with translation, end to end works better</li>
<li>estimating a childs age from a hand xray: there isn’t much data so multistep approach works better.</li>
</ul>
</section>
<section id="whether-to-use-end-to-end-deep-learning" class="level4">
<h4 class="anchored" data-anchor-id="whether-to-use-end-to-end-deep-learning">Whether to use end-to-end deep learning</h4>
<ul>
<li>benefits of end-to-end deep learning:
<ul>
<li>lets the data speak - if we have enough data a large enough NN will figure it out</li>
<li>less hand designing of components needed</li>
</ul></li>
<li>cons
<ul>
<li>may need large amount of data</li>
<li>may exclude potentially useful hand designed components</li>
</ul></li>
<li>learning algos have two main sources of knowledge: the data and human knowledge</li>
<li>key q: do we have enough data to learn a function of the complexity to map x to y?</li>
<li>in a self driving car, we have <code>image/radar/lidar -&gt; cars/pedestrians -&gt; route -&gt; steering</code> and currently some of these things are done with non deep learning approaches</li>
<li>it would be great to input data and get a steering/accel output, but this isn’t very promising yet for self driving cars</li>
</ul>
</section>
</section>
<section id="ruslan-salakhutdinov-interview" class="level3">
<h3 class="anchored" data-anchor-id="ruslan-salakhutdinov-interview">Ruslan Salakhutdinov interview</h3>
<ul>
<li>Director of AI research at Apple <a href="https://twitter.com/rsalakhu?lang=en">twitter</a>, <a href="https://www.linkedin.com/in/ruslan-salakhutdinov-53a0b610">linkedin</a></li>
<li>see his <a href="http://www.cs.cmu.edu/~rsalakhu/jsm2018.html">slides on his talk on the deep learning revolution</a></li>
<li>boltzmann machines and deep boltzmann machines are very powerful but we haven’t figured out how to use them yet</li>
<li>generative modelling is exciting, expects a lots of progress in the near future</li>
<li>companies have lots of unlabelled data but we haven’t figured out how to use it</li>
<li>advice for new researchers:
<ul>
<li>try different and new things. with neural networks too many ppl wrote them off as non-convex problems impossible to optimize.</li>
<li>code backprop yourself once to understand it</li>
<li>phd vsd industry: more freedom in academia for long term problems, but industry research is very exciting and well funded, impacts millions of users</li>
</ul></li>
<li>exciting areas: unsupervised learning, deep reinforcement learning, NLP</li>
</ul>
<hr>
<p>course <a href="https://www.coursera.org/account/accomplishments/certificate/QZESAQHSKF3K">done and dusted</a>:</p>
<p><img src="img/deeplearningai-3-of-5-cert.png" class="img-fluid"></p>


<!-- -->

</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "deeplearning.ai: Structuring Machine Learning Projects"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2018-01-01</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> notes for part 3 of the deeplearning.ai course</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> /images/deeplearningai-3-of-5-cert.png</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">- courses</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu"># deeplearning.ai: Structuring Machine Learning Projects</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>This course covers how to think about and improve machine learning systems.</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; You will learn how to build a successful machine learning project. If you aspire to be a technical leader in AI, and know how to set direction for your team's work, this course will show you how.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>**Course Resources**</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Course home</span><span class="co">](https://www.coursera.org/learn/machine-learning-projects/home/welcome)</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Discussion forum</span><span class="co">](https://www.coursera.org/learn/machine-learning-projects/discussions)</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Week 1: ML Strategy</span><span class="co">](#week-1-ml-strategy)</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Orthogonalization</span><span class="co">](#orthogonalization)</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Setting up your goal</span><span class="co">](#setting-up-your-goal)</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Single number evaluation metric</span><span class="co">](#single-number-evaluation-metric)</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Satisficing and Optimizing metric</span><span class="co">](#satisficing-and-optimizing-metric)</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Train/dev/test distributions</span><span class="co">](#traindevtest-distributions)</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Size of the dev and test sets</span><span class="co">](#size-of-the-dev-and-test-sets)</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">When to change dev/test sets and metrics</span><span class="co">](#when-to-change-devtest-sets-and-metrics)</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Comparing to human-level performance</span><span class="co">](#comparing-to-human-level-performance)</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Why human-level performance?</span><span class="co">](#why-human-level-performance)</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Avoidable bias</span><span class="co">](#avoidable-bias)</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Understanding human-level performance</span><span class="co">](#understanding-human-level-performance)</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Surpassing human-level performance</span><span class="co">](#surpassing-human-level-performance)</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Improving your model performance</span><span class="co">](#improving-your-model-performance)</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Andrej Karpathy interview</span><span class="co">](#andrej-karpathy-interview)</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Week 2: More ML Strategy</span><span class="co">](#week-2-more-ml-strategy)</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Error Analysis</span><span class="co">](#error-analysis)</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Carrying out error analysis</span><span class="co">](#carrying-out-error-analysis)</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Cleaning up incorrectly labeled data</span><span class="co">](#cleaning-up-incorrectly-labeled-data)</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Build your first system quickly, then iterate</span><span class="co">](#build-your-first-system-quickly-then-iterate)</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Mismatched training and dev/test data</span><span class="co">](#mismatched-training-and-devtest-data)</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Training and testing on different distributions</span><span class="co">](#training-and-testing-on-different-distributions)</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Bias and Variance with mismatched data distributions</span><span class="co">](#bias-and-variance-with-mismatched-data-distributions)</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Addressing data mismatch</span><span class="co">](#addressing-data-mismatch)</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Learning from multiple tasks</span><span class="co">](#learning-from-multiple-tasks)</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Transfer learning</span><span class="co">](#transfer-learning)</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Multi-task learning</span><span class="co">](#multi-task-learning)</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">End-to-end deep learning</span><span class="co">](#end-to-end-deep-learning)</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">What is end-to-end deep learning</span><span class="co">](#what-is-end-to-end-deep-learning)</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span><span class="co">[</span><span class="ot">Whether to use end-to-end deep learning</span><span class="co">](#whether-to-use-end-to-end-deep-learning)</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Ruslan Salakhutdinov interview</span><span class="co">](#ruslan-salakhutdinov-interview)</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 1: ML Strategy</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>There are lots of ways to improve a deep learning system, so its important to sse quick and effective ways to figure out the most promising things to try and and improve.</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="fu">### Orthogonalization</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>old school tv's had a number of knobs to tune the picture - all the settings made it very hard to get the picture perfect</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>cars have orthogonal controls - a steering and speed which effect two different things making it easier to control. If we have controls which effect the steering and speed at the same time it would make it much harder to get the speed and steering angle we wanted.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we have a chain of assumptions in ML: fit training set on cost func, fit dev set, fit test set, then perform well in the real world and we want to have different set of knobs to tune each part.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ideally we have a number of controls which do one task well without effecting other things too much. </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>of course, some controls apply across many layers and are still useful, like early stopping</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="fu">### Setting up your goal</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Single number evaluation metric</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>set up a single real number to evaluate performance before starting out on a project</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a well defined dev set and a single metric speeds up the iterative process of developing a good model</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>looking at a simple cat classifier:</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>| Classifier | Precision | Recall |</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>| ---------- | --------- | ------ |</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>| A          | 95%       | 90%    |</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>| B          | 98%       | 85%    |</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Precision**: of the examples our classifier says are cats, what percentage is actually right</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recall**:  what % of actual cats are correctly classified</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The problem with using precision and recall is it can make it hard to figure out which classifier is better</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">F1 Score</span><span class="co">](https://www.wikiwand.com/en/F1_score)</span> is the harmonic average of precision and recall using $F1 = 2 / ((1/P) + (1/R))$ or $2 * (precision * recall) / (precision + recall)$</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>F1 score is usefeul as it balances precision and recall, rather than just taking the simple average, which would favour outliers</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to summarize, have a single number metric (this could be an average of several metrics) and a good dev set</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Satisficing and Optimizing metric</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>its not easy to setup a single number - we might narrow things down to a single number, accuracy, but also want to evaluate running time</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>solve this by picking one metric to optimize, and satisfy the other metric by picking a threshold, like all running times below 1000ms are good enough.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>for voice recognition, like on Amazon Alexa, we have metrics for how long humans are ok to wait, so we can just use that number as a threshold</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so, we have a make metric to optimize, and any number of other metrics which we satisfy with thresholds. </span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a> #### Train/dev/test distributions</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>dev (cross validation set) and test (the final holdout data) sets have to come from the same distribution.</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>for example, if we have data from different regions, don't say us/uk/europe is the dev set and asia is the test set - regions will have differences.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>an ML team wasted time optimizing loan approvals on medium income zip codes, but was testing on low income zip codes.</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>choose a dev and test set to reflect data you expect to get in the future and consider important to do well on.</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Size of the dev and test sets</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>old rule of thumb for train/dev/test: 60/20/20 - worked for smaller data.</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>but now we have much larger data sets, so for 1M data set, 1% or 10K might be enough for a test set.</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>deep learning is data hungry so we want to feed it as much data as possible for training</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the test set helps us evaluate the overall system, so it has to be big enough to give us high confidence.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>this will vary depending on the data set.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>sometimes we might not need a test set at all.</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="fu">#### When to change dev/test sets and metrics</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>say we've built two cat classifiers, A has 3% error, B has 5% error.</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A is better, but lets through porn images. B stops all the porn images, so even though it has higher error, B is better algorithm.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so we want to change our metrics here, say adding a weight to penalize porn images</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>think of machine learning as having two separate steps:</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>1. figure out the metric</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>2. worry about how to actually do well on the metric</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>other things happen, like our image classifier performs well on our data set, but users upload bad quality pictures which lower performance, so change metric and/or the dev set to better capture what we need our algorithm to actually do.</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparing to human-level performance</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Why human-level performance?</span></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>two main reasons we compare to human level performance:</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>ML is getting better so its become feasible to compare to human level performance in many applications.</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>the workflow of designing and building ML systems is much more efficient when comparing to what humans also do.</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>for many problems, progress is rapid approaching human level performance, and slows down upon reaching it. the hope is that its reaching a theoretical limit, called the Bayes optimal error.</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bayes optimal error** is the best possible error</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>for tasks humans are good at, there isn't much range b/w human error and the bayes optimal error.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>when our ML algo is worse than humans, get humans to:</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>give us more data, like label images, translate text, etc.</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>manual analysis errors - why did a human get it right and algo get it wrong?</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>better analysis of bias/variance</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Avoidable bias</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>humans are great at image classification, so looking at two image classification algos:</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>|                | Bias Example | Variance Example |</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>| -------------- | ------------ | ---------------- |</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>| Humans         | 1%           | 7.5%             |</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>| Training error | 8%           | 8%               |</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>| Dev Error      | 10%          | 10%              |</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the left example illustrates bias - since humans are doing much better than the algo, we focus on improving training error.</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the right example shows that we are close to human error - so we focus on reducing the variance</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if we are doing better than Bayes error we're overfitting.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>having an estimate of the bayes optimal error helps us to focus on whether to reduce bias or variance.</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>avoidable bias: training error - human level error</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>variance: dev error - training error</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Understanding human-level performance</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>there are multiple levels of human performance - choose what matters and what we want to achieve for our system</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>do we use a typical doctors error level, an experienced doctors, or the lower error level from a team of experienced doctors.</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>surpassing an average radiologist might mean our system is good enough to deploy</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>use human level error as a proxy for Bayes error. </span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>An error analysis example from medical classification, where say human error ranges from 0.5-1%:</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>| Error       | Bias Example | Variance Example |</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>| ----------- | ------------ | ---------------- |</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>| Human/Bayes | 1%           | 1%               |</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>| Training    | 5%           | 1%               |</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>| Dev         | 6%           | 5%               |</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the left column we need to concentrate on reducing the training error - the variance, and the human error we pick doesn't matter.</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the right col we need to concentrate on the dev error - i.e the variance, and picking the lower range of human error is more important since we are close to human level performance.</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so we have a more nuanced view of error, and using bayes error instead of zero error leads to better and faster decisions on reducing bias or variance.</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Surpassing human-level performance</span></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ml gets harder as we approach/surpass human level performance</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>when we've surpassed human level performance, are we overfitting, or is the bayes error lower than human error.</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>some applications have surpassed human level: online advertising, product recommendation, loan approval, logistics</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>all these examples are learning from structured data, not natural perception problems which humans are very good at</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>teams have access to heaps of data</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>computers haven gotten to single human level at certain perception tasks, like image recognition, speech.</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Improving your model performance</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>two fundamental assumptions of supervised learning:</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we can fit the training set pretty well, or avoid bias</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>the training set performance generalizes well to the dev/test set - achieve low variance</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to improve a deep learning supervised system</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>for improving bias:</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>train bigger model</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>train longer or use better optimization algo (RMSprop, Adam, momentum, etc)</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>try other model architectures, hyperparameter search</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>improve variance:</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>more data</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>regularization (L2, dropout, data augmentation)</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>NN architecture, hyperparameter search</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="fu">### Andrej Karpathy interview</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>before NN's ml/ai was a lot of graphs, tree pruning, not very satisfying - NN's actually felt like AI vs the old school AI techniques</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>before, humans wrote code to do something, with neural networks / machine learning humans write the optimization algo and specify inputs/outputs and the computers write code</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>while working on cifar10, had predicted an error rate of 10%, but we're now down to 2-3%.</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>built a javascript interface to show himself imagenet images and classify them</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>famous for putting his deep learning stanford class online</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>understand of deep learning has changed:</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>surprised by how general deep learning is - no one saw how well it would work</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>amazed at how you can take pre trained networks and apply them to other tasks</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>people are crushing tasks one after the other with transfer learning</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>surprised that unsupervised learning hasn't worked so well</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>has been thinking about the future of AI, thinks will split into two directions:</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>applied AI, where ppl train NN's to do something, generally supervised learning</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>artificial general intelligence, working on dynamic systems to do everything a human can</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>thinks the approach to do one thing at a time, like with current neural nets which recoginze images, or do speech etc, won't lead to AGI, we need a single kind of NN which learns all the tasks a human can do - see <span class="co">[</span><span class="ot">his short story on how this might look</span><span class="co">](http://karpathy.github.io/2015/11/14/ai/)</span>.</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>people liked CS213N becuase it didn't abstract away things, it works through the low-level details. Implementing stuff is the best way to learn it.</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 2: More ML Strategy</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="fu">### Error Analysis</span></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Carrying out error analysis</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>manually examining what your algo is doing gives insight</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>e.g looking at a 100 misclassified dev set examples, see whats the biggest type of error and work on fixing that. i.e we want to work on the errors which make up the bulk of our problem, rather than the lower percentage errors.</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>error analysis helps us pick useful actions which will have meaningful improvements.</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can evaluate multiple ideas in parallel - use a spreadsheet to help decide:</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="al">![](img/eval-multiple-ideas.png)</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so summarize errors, find categories, prioritize important ones</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Cleaning up incorrectly labeled data</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>sometimes its worthwhile to check training sets for mislabelled images</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>deep neural networks are quite robust to random errors in the training set, so few mistakes are ok</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>but systematic errors aren't ok, like labelling all white dogs as cats</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>modify our error spreadsheet above to have a mis-labelled category, we should always go after the biggest cause of error first</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>correcting dev/test set examples:</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>apply same process to dev/test so they continue to come from the same distribution</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>consider examining examples the algo got right as well as the ones it got wrong</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we might decide to only correct labels in the dev/test sets and not go through the bigger training set, so dev/test data may now come from slightly different distrubutions. This is ok, long as both dev/test have the same distribution, and the train set is a slightly different distribution</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Build your first system quickly, then iterate</span></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>there are many ways to make a speech recognition system more robust. More generally, for any ML project there are 50 different directions to improve a ml system</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>quickly set up a dev/test set and metric, build a initial system, then use Bias/Variance analysis and error analysis to prioritize next steps</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a lot of value in the initial ML system is to help us prioritize future efforts. </span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mismatched training and dev/test data</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Training and testing on different distributions</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>deep learning needs big data, so often teams end up shoving whatever they can find into a training set, so you end up with different distributions b/w train and test/dev sets.</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>e.g we can get 200k cat pictures from web pages, which are good quality and in large numbers, and 10k pictures from a mobile app which are crappy.</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so what can we do:</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>combine the datasets and randomly shuffle into a train/dev/test split (205k, 2,500, 2,500), so everything is from the same distribution</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>the problem here is that 2,381 out of 2,500 images in the dev/test set will come from the mobile app</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>make the training set use all 200k from the web plus 5K from the app, and test/dev set will be 2,500 images each from the app. This sets the target what we want it to be, even though the distributions are no different.</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a real example of a speech recognizer for directions - we are only listening for sentences like "find the nearest gas station" but we can train on all kinds of speech data, while the dev/test sets are from our specific area. If our specific application has enough data we can add some of it to the training set as well.</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Bias and Variance with mismatched data distributions</span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the way we analyze bias and variance changes when train dev/test sets are from different distributions</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so we need a training-dev set which has the same distribution as the training set, and isn't used for training. so we would have error analysis like:</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a> |                    | Variance Problem | data mismatch Problem |</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a> | ------------------ | ---------------- | --------------------- |</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a> | Training Error     | 1%               | 1%                    |</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a> | Training-dev error | 9%               | 1.5%                  |</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a> | Dev Error          | 10%              | 10%                   |</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Addressing data mismatch</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>carry out manual error analysis to understand difference b/w training and dev/test sets</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we might find errors like a lot of our dev/test data is nosier than training set</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so then we can collect more training data, or make it similar to dev/test data</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>use artificial data synthesis to make the training data more similar to dev set:</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>combine some of the training data with something to make it similar to the test/dev distribution, like recorded background noise, or generate new examples</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>be careful about simulating data from a small subset of space, like background noise which isn't representative of actual background noise </span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can synthesize data which passes the human test but it could lead to over fitting as our synthetic data might just be making a subset of the dataset.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="fu">### Learning from multiple tasks</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Transfer learning</span></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>apply knowledge from one task to another</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>take a image recognizer NN, delete the last layer, create a new layer with random weights and retrain the NN on the new dataset. (called fine tuning)</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we can train only the last layer, or given enough data we can train the entire network.</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>this works as a lot of the low level layers are recognizing structures and features which transfers across to different tasks</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>transfer learning makes sense when:</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>task A and B have the same input X (image, speech)</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>we have a lot of data for task A and less data for task B</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>the low level features are similar for both tasks</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>obviously, having a large dataset for the actual problem is ideal, but often we end up having better/more data for a well known problem, like ImageNet for images, and a lot less for what we want to do (say radiology photos).</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Multi-task learning</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>try to have one NN learn multiple tasks - like a simple self driving car has to detect several things: stop signs, pedestrians, cars, traffic lights, etc</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so the NN predicts a output vector where each position indicates whether something is there or not. (one image has multiple labels)</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we could have a NN for each type of object, so when does multi-task learning make sense?</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>low level features are shared across each object.</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>the amount of data for each task is similar</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>can train a big enough NN to do well on all tasks (can perform better than single NNs)</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in practice, multi-task is used a lot less than transfer learning - though is used a lot in computer vision</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="fu">### End-to-end deep learning</span></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="fu">#### What is end-to-end deep learning</span></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>there are some learning systems which need multiple stages of processing, like speech recognition and vision - engineers had spent years engineering feature pipelines</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>and end to end deep learning neural network replaces all these multiple stages with a single neural network</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>but sometimes you don't want to just feed raw data, like with face recognition - it works better if the image is zoomed and cropped to the face - so you have two deep learning stages:</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>figure out where is the face</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>now figure out whose face it is</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>when we have heaps of data, like with translation, end to end works better </span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>estimating a childs age from a hand xray: there isn't much data so multistep approach works better.</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Whether to use end-to-end deep learning</span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>benefits of end-to-end deep learning:</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>lets the data speak - if we have enough data a large enough NN will figure it out</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>less hand designing of components needed</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>cons</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>may need large amount of data</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>may exclude potentially useful hand designed components</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>learning algos have two main sources of knowledge: the data and human knowledge</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>key q: do we have enough data to learn a function of the complexity to map x to y?</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in a self driving car, we have <span class="in">`image/radar/lidar -&gt; cars/pedestrians -&gt; route -&gt; steering`</span> and currently some of these things are done with non deep learning approaches</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>it would be great to input data and get a steering/accel output, but this isn't very promising yet for self driving cars</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ruslan Salakhutdinov interview</span></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Director of AI research at Apple <span class="co">[</span><span class="ot">twitter</span><span class="co">](https://twitter.com/rsalakhu?lang=en)</span>, <span class="co">[</span><span class="ot">linkedin</span><span class="co">](https://www.linkedin.com/in/ruslan-salakhutdinov-53a0b610)</span></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>see his <span class="co">[</span><span class="ot">slides on his talk on the deep learning revolution</span><span class="co">](http://www.cs.cmu.edu/~rsalakhu/jsm2018.html)</span></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>boltzmann machines and deep boltzmann machines are very powerful but we haven't figured out how to use them yet</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>generative modelling is exciting, expects a lots of progress in the near future</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>companies have lots of unlabelled data but we haven't figured out how to use it</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>advice for new researchers:</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>try different and new things. with neural networks too many ppl wrote them off as non-convex problems impossible to optimize. </span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>code backprop yourself once to understand it</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>phd vsd industry: more freedom in academia for long term problems, but industry research is very exciting and well funded, impacts millions of users</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>exciting areas: unsupervised learning, deep reinforcement learning, NLP</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>course <span class="co">[</span><span class="ot">done and dusted</span><span class="co">](https://www.coursera.org/account/accomplishments/certificate/QZESAQHSKF3K)</span>:</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="al">![](img/deeplearningai-3-of-5-cert.png)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>