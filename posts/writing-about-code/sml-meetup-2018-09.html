<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="KO">
<meta name="dcterms.date" content="2018-09-20">
<meta name="description" content="notes from the meetup">

<title>khalido.org - SML 2018-09: Deep Reinforcement Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">khalido.org</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/khalido" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/KO" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">SML 2018-09: Deep Reinforcement Learning</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          notes from the meetup
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">meetup</div>
                <div class="quarto-category">data science</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>KO </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 20, 2018</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sml-2018-09-deep-reinforcement-learning" id="toc-sml-2018-09-deep-reinforcement-learning" class="nav-link active" data-scroll-target="#sml-2018-09-deep-reinforcement-learning">SML 2018-09: Deep Reinforcement Learning</a>
  <ul class="collapse">
  <li><a href="#kosuke-fujimoto-how-can-we-innovate-our-workstyle-at-construction-sites-with-image-classification" id="toc-kosuke-fujimoto-how-can-we-innovate-our-workstyle-at-construction-sites-with-image-classification" class="nav-link" data-scroll-target="#kosuke-fujimoto-how-can-we-innovate-our-workstyle-at-construction-sites-with-image-classification">Kosuke Fujimoto: How can we innovate our workstyle at construction sites with Image Classification?</a></li>
  <li><a href="#krit-kamtuo-using-batch-ai-to-train-nlp-based-on-tensorflow-and-cntk-in-the-retail-industry" id="toc-krit-kamtuo-using-batch-ai-to-train-nlp-based-on-tensorflow-and-cntk-in-the-retail-industry" class="nav-link" data-scroll-target="#krit-kamtuo-using-batch-ai-to-train-nlp-based-on-tensorflow-and-cntk-in-the-retail-industry">Krit Kamtuo: Using Batch AI to train NLP based on Tensorflow and CNTK in the retail industry</a></li>
  <li><a href="#matt-gibson-learning-with-not-quite-the-right-labels" id="toc-matt-gibson-learning-with-not-quite-the-right-labels" class="nav-link" data-scroll-target="#matt-gibson-learning-with-not-quite-the-right-labels">Matt Gibson: Learning with not quite the right labels</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="sml-2018-09-deep-reinforcement-learning" class="level1">
<h1>SML 2018-09: Deep Reinforcement Learning</h1>
<p>SML’s <a href="https://www.meetup.com/Sydney-Machine-Learning/events/253797245/">2018-09 meetup</a>.</p>
<ul>
<li><a href="https://www.eventbrite.com.au/e/emerge-2018-stem-careers-expo-tickets-46959173151">STEM Careers expo on Thu 6th Sep</a></li>
</ul>
<p>the talks:</p>
<section id="kosuke-fujimoto-how-can-we-innovate-our-workstyle-at-construction-sites-with-image-classification" class="level2">
<h2 class="anchored" data-anchor-id="kosuke-fujimoto-how-can-we-innovate-our-workstyle-at-construction-sites-with-image-classification">Kosuke Fujimoto: How can we innovate our workstyle at construction sites with Image Classification?</h2>
<blockquote class="blockquote">
<p>Kosuke, Takenaka Corporation is one of the top 5 largest construction companies in Japan. Their site supervisors perform site visits, record the progress of ongoing construction as well as assign appropriate resourcing from their workforce by writing up the report every evening. This involves taking a lot of photos and organizing them based on the construction progress.</p>
</blockquote>
<blockquote class="blockquote">
<p>In this talk, I walk you through an effort by Takenaka with help from Microsoft to automatically organize photos utilizing Keras and Transfer Learning to make workstyle innovation at construction sites possible.</p>
</blockquote>
<ul>
<li><a href="https://github.com/fujikosu">github</a></li>
<li>Takanaka is a huge consturction company in Japan</li>
<li>so much demand that only 5.7% of employees get 2 days a week, plus working population is decreasing
<ul>
<li>need to make work more efficent</li>
</ul></li>
<li>lots of photo related tasks - construction management relies on photos for order, evidence &amp; education
<ul>
<li>manually organised, takes lots of time</li>
<li>100 millions photos taken yearly</li>
</ul></li>
<li>Used transfer learning with 10K photos split: train/test/valid split: 7,2,1 for a trial</li>
<li>You don’t need heaps of photos for transfer learning, the pretrained models have already been trained on heaps of data.</li>
<li>Keras has a <a href="https://keras.io/applications/">bunch of pretrained models</a> ready to use.</li>
<li>We have to run a bunch of experiments to figure out stuff. <a href="https://docs.microsoft.com/en-us/azure/machine-learning/desktop-workbench/experimentation-service-configuration">Azure Machine Learning Services has lots of tools for experimentation</a>.</li>
<li>see https://github.com/fujikosu/aml-keras-image-recognition</li>
<li>think about data augmentation - Keras’s built in functions for this are great</li>
</ul>
<p>The company’s example was really powerful - a very small amount of deep learning solved a very big problem, since transfer learning and the cloud is making vision problems much easier to deal with.</p>
</section>
<section id="krit-kamtuo-using-batch-ai-to-train-nlp-based-on-tensorflow-and-cntk-in-the-retail-industry" class="level2">
<h2 class="anchored" data-anchor-id="krit-kamtuo-using-batch-ai-to-train-nlp-based-on-tensorflow-and-cntk-in-the-retail-industry">Krit Kamtuo: Using Batch AI to train NLP based on Tensorflow and CNTK in the retail industry</h2>
<blockquote class="blockquote">
<p>Currently, SSG.COM, the subsidiary of Shinsegae Group the largest retailer in South Korea, is developing an AI chatbot service based on deep learning. It was decided that the internet as as service-based architecture is not efficient because it requires additional resources if the operation production scale is increased.</p>
<p>We will discuss why the AI model training layer does not have to be running at all times but the GPU-supported VM should be used continuously, to reduce costs to SSG.COM.</p>
</blockquote>
<ul>
<li><span class="citation" data-cites="kritcs18">@kritcs18</span>, <a href="https://github.com/taeyo">github</a></li>
<li>ssg.com is the largest retailer in South Korea, was working on a AI chatbot based on deep learning</li>
<li>pretty complex and expensive architecture, wanted to migrate to the cloud (PaaS)</li>
<li>shifed to a serverless model with API gateways</li>
<li><a href="https://azure.microsoft.com/en-us/services/batch-ai/">MS Azure Batch AI</a> takes care of all the hardware, you focus on the work which needs to happen. Looks pretty pimp. The era of spinning up your own VM is fast ending.
<ul>
<li>suited for bigCo for sure, but for personal experiments there is too much configuration code (for now).</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>Batch AI is a managed service that enables data scientists and AI researchers to train AI and other machine learning models on clusters of Azure virtual machines, including VMs with GPU support. You describe the requirements of your job, where to find the inputs and store the outputs, and Batch AI handles the rest.</p>
</blockquote>
<p>Interesting becuase companies are moving from running their own hardware, to hardware in the cloud, and now on to running apps themselves with the hardware spin up spin down somewhat abstracted (or in the process of getting so).</p>
</section>
<section id="matt-gibson-learning-with-not-quite-the-right-labels" class="level2">
<h2 class="anchored" data-anchor-id="matt-gibson-learning-with-not-quite-the-right-labels">Matt Gibson: Learning with not quite the right labels</h2>
<blockquote class="blockquote">
<p>Having the right data is often as important as having the right model for building effective computer vision systems. Even if you have enough data, what do you do when don’t have the right labels? Common problems arising in image understanding include only having partially labelled data, have the wrong type of labels and noisy labels. Broadly these problems can be addressed by an area of research called weakly supervised learning. I will give an overview of some strategies coming from weakly supervised learning to help train good predictive models in the presence of these difficulties. The tools used will include ConvNets combined with some interesting applications of familiar friends such as the EM algorithm and graph-based clustering.</p>
</blockquote>
<ul>
<li></li>
</ul>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "SML 2018-09: Deep Reinforcement Learning"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "notes from the meetup"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2018-09-20</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">- meetup</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">- data science</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu"># SML 2018-09: Deep Reinforcement Learning</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>SML's <span class="co">[</span><span class="ot">2018-09 meetup</span><span class="co">](https://www.meetup.com/Sydney-Machine-Learning/events/253797245/)</span>.</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">STEM Careers expo on Thu 6th Sep</span><span class="co">](https://www.eventbrite.com.au/e/emerge-2018-stem-careers-expo-tickets-46959173151)</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>the talks:</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Kosuke Fujimoto: How can we innovate our workstyle at construction sites with Image Classification?</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Kosuke, Takenaka Corporation is one of the top 5 largest construction companies in Japan. Their site supervisors perform site visits, record the progress of ongoing construction as well as assign appropriate resourcing from their workforce by writing up the report every evening. This involves taking a lot of photos and organizing them based on the construction progress.</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In this talk, I walk you through an effort by Takenaka with help from Microsoft to automatically organize photos utilizing Keras and Transfer Learning to make workstyle innovation at construction sites possible.</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">github</span><span class="co">](https://github.com/fujikosu)</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Takanaka is a huge consturction company in Japan</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>so much demand that only 5.7% of employees get 2 days a week, plus working population is decreasing</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>need to make work more efficent</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>lots of photo related tasks - construction management relies on photos for order, evidence &amp; education</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>manually organised, takes lots of time</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>100 millions photos taken yearly</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Used transfer learning with 10K photos split: train/test/valid split: 7,2,1 for a trial</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>You don't need heaps of photos for transfer learning, the pretrained models have already been trained on heaps of data. </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Keras has a <span class="co">[</span><span class="ot">bunch of pretrained models</span><span class="co">](https://keras.io/applications/)</span> ready to use.</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We have to run a bunch of experiments to figure out stuff. <span class="co">[</span><span class="ot">Azure Machine Learning Services has lots of tools for experimentation</span><span class="co">](https://docs.microsoft.com/en-us/azure/machine-learning/desktop-workbench/experimentation-service-configuration)</span>.</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>see https://github.com/fujikosu/aml-keras-image-recognition</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>think about data augmentation - Keras's built in functions for this are great </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>The company's example was really powerful - a very small amount of deep learning solved a very big problem, since transfer learning and the cloud is making vision problems much easier to deal with.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Krit Kamtuo: Using Batch AI to train NLP based on Tensorflow and CNTK in the retail industry</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Currently, SSG.COM, the subsidiary of Shinsegae Group the largest retailer in South Korea, is developing an AI chatbot service based on deep learning. It was decided that the internet as as service-based architecture is not efficient because it requires additional resources if the operation production scale is increased.</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We will discuss why the AI model training layer does not have to be running at all times but the GPU-supported VM should be used continuously, to reduce costs to SSG.COM.</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>@kritcs18, <span class="co">[</span><span class="ot">github</span><span class="co">](https://github.com/taeyo)</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ssg.com is the largest retailer in South Korea, was working on a AI chatbot based on deep learning</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>pretty complex and expensive architecture, wanted to migrate to the cloud (PaaS)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>shifed to a serverless model with API gateways</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">MS Azure Batch AI</span><span class="co">](https://azure.microsoft.com/en-us/services/batch-ai/)</span> takes care of all the hardware, you focus on the work which needs to happen. Looks pretty pimp. The era of spinning up your own VM is fast ending.</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>suited for bigCo for sure, but for personal experiments there is too much configuration code (for now). </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Batch AI is a managed service that enables data scientists and AI researchers to train AI and other machine learning models on clusters of Azure virtual machines, including VMs with GPU support. You describe the requirements of your job, where to find the inputs and store the outputs, and Batch AI handles the rest.</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>Interesting becuase companies are moving from running their own hardware, to hardware in the cloud, and now on to running apps themselves with the hardware spin up spin down somewhat abstracted (or in the process of getting so).</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="fu">## Matt Gibson: Learning with not quite the right labels</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Having the right data is often as important as having the right model for building effective computer vision systems. Even if you have enough data, what do you do when don't have the right labels? Common problems arising in image understanding include only having partially labelled data, have the wrong type of labels and noisy labels. Broadly these problems can be addressed by an area of research called weakly supervised learning. I will give an overview of some strategies coming from weakly supervised learning to help train good predictive models in the presence of these difficulties. The tools used will include ConvNets combined with some interesting applications of familiar friends such as the EM algorithm and graph-based clustering.</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>